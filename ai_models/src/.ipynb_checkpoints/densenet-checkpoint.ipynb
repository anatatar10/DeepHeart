{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T07:06:27.983424Z",
     "start_time": "2025-05-26T07:06:27.963651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, hamming_loss, multilabel_confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# Parameters\n",
    "image_dir = \"/Users/anatatar/Desktop/Licenta/ai_models/data/ecg_images_final\"\n",
    "csv_path = \"/Users/anatatar/Desktop/Licenta/ai_models/data/labeled_ecg_images.csv\"\n",
    "target_classes = ['NORM', 'MI', 'STTC', 'CD', 'HYP']\n",
    "image_size = (224, 224)\n",
    "random_state = 42\n",
    "\n",
    "os.makedirs(\"densenet\", exist_ok=True)\n"
   ],
   "id": "a92dd64e7710be8a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T07:07:13.264706Z",
     "start_time": "2025-05-26T07:06:28.026746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def find_image_path(filename):\n",
    "    for folder in os.listdir(image_dir):\n",
    "        path = os.path.join(image_dir, folder, filename)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "df['image_path'] = df['filename'].apply(find_image_path)\n",
    "df = df[df['image_path'].notnull()]\n",
    "print(f\"✅ Total usable samples (multi-label): {len(df)}\")\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=random_state)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=random_state)\n",
    "\n",
    "def load_or_cache_images(df_subset, name):\n",
    "    X_path = f\"densenet/X_{name}.npy\"\n",
    "    y_path = f\"densenet/y_{name}.npy\"\n",
    "    if os.path.exists(X_path) and os.path.exists(y_path):\n",
    "        print(f\"✅ Loading cached {name} data...\")\n",
    "        X = np.load(X_path)\n",
    "        y = np.load(y_path)\n",
    "    else:\n",
    "        print(f\"⏳ Caching {name} data...\")\n",
    "        X, y = [], []\n",
    "        for _, row in tqdm(df_subset.iterrows(), total=len(df_subset), desc=f\"Loading {name} images\"):\n",
    "            img = load_img(row['image_path'], color_mode='rgb', target_size=image_size)\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            label_vector = row[target_classes].values.astype(np.float32)\n",
    "            X.append(img_array)\n",
    "            y.append(label_vector)\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        np.save(X_path, X)\n",
    "        np.save(y_path, y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = load_or_cache_images(train_df, \"train\")\n",
    "X_val, y_val = load_or_cache_images(val_df, \"val\")\n",
    "X_test, y_test = load_or_cache_images(test_df, \"test\")\n"
   ],
   "id": "7a66c24f221a6ecf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total usable samples (multi-label): 21799\n",
      "⏳ Caching train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train images: 100%|██████████| 15749/15749 [00:14<00:00, 1098.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Caching val data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val images: 100%|██████████| 2780/2780 [00:02<00:00, 985.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Caching test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images: 100%|██████████| 3270/3270 [00:03<00:00, 929.31it/s] \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-26T07:07:13.320762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(len(target_classes), activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = i >= len(base_model.layers) - 40\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[AUC(curve='ROC', multi_label=True, name='auc'),\n",
    "             Precision(name='precision'),\n",
    "             Recall(name='recall'),\n",
    "             'accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=25,\n",
    "                    batch_size=8,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(\"densenet/densenet_model.h5\")\n",
    "with open(\"densenet/history.json\", \"w\") as f:\n",
    "    json.dump(history.history, f)\n"
   ],
   "id": "e99058239953d127",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001B[1m   1/1969\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:03:46\u001B[0m 6s/step - accuracy: 0.0000e+00 - auc: 0.2305 - loss: 1.2380 - precision: 0.0870 - recall: 0.2222"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred_bin = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "np.save(\"densenet/y_test.npy\", y_test)\n",
    "np.save(\"densenet/y_pred_bin.npy\", y_pred_bin)\n",
    "np.save(\"densenet/y_pred_probs.npy\", y_pred_probs)\n",
    "\n",
    "report = classification_report(y_test, y_pred_bin, target_names=target_classes, zero_division=0)\n",
    "print(report)\n",
    "\n",
    "cm = multilabel_confusion_matrix(y_test, y_pred_bin)\n",
    "\n",
    "for i, name in enumerate(target_classes):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm[i], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Pred Neg', 'Pred Pos'],\n",
    "                yticklabels=['Actual Neg', 'Actual Pos'])\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "401ab32d1cb60f79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "fdf65ef248bd09fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def generate_grad_cam(model, image_array, class_index, output_path):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(index=-3).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([image_array]))\n",
    "        loss = predictions[:, class_index]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    cam = np.zeros(conv_outputs.shape[0:2], dtype=np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * conv_outputs[:, :, i]\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam.numpy(), image_size)\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max()\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    img = np.uint8(255 * image_array)\n",
    "    overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "    cv2.imwrite(output_path, overlay)\n",
    "    print(f\"✅ Grad-CAM saved to {output_path}\")\n",
    "\n",
    "for i, class_name in enumerate(target_classes):\n",
    "    generate_grad_cam(model, X_test[0], class_index=i, output_path=f\"densenet/gradcam_{class_name}_sample0.png\")\n"
   ],
   "id": "14b53dd8fbfdf13e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
